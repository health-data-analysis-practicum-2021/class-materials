---
title: "Class 2-3: Continuing with Module 2"
author: "Health Data Analysis Practicum (AS.280.347)"
date: "March 8, 2021"
output: 
  html_document:
    toc: true
    toc_float: 
      toc_collapsed: true
    toc_depth: 3
    number_sections: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = TRUE)
knitr::opts_knit$set(root.dir = "/cloud/project")
```

## Module 2: Factors that are associated with development of hypertension

Recall that our main questions of interest are:

  * Question 2.1: What factors measured in the NYC HANES survey are associated with having hypertension?
  * Question 2.2: How do our estimates from survey-weighted logistic regression differ from those where we ignore survey weights?


The data science learning objectives for this module include:

  * Understand the components of a data analysis report
  * Gain experience performing data cleaning, and assessing whether you have been successful
  * Practice selecting data visualizations that fit into the context of your statistical analysis

The statistical learning objectives for this module include:

  * Gain further experience with logistic regression and selecting an appropriate model for your question
  * Understand what a survey-weighted analysis is and how/when we perform one
  * Learn how to select survey weights for unbalanced data

## Reminder: What are the data?

For this case study, we will use data from the [New York City (NYC) Health and Nutrition Examination Survey (NYC HANES)](http://nychanes.org/){target="_blank"}, modeled on the [National Health and Nutrition Examination Survey (NHANES)](https://wwwn.cdc.gov/nchs/nhanes/default.aspx){target="_blank"}. NHANES is a population-based, cross-sectional study with data collected from a physical examination and laboratory tests, as well as a face-to-face interview and an audio computer-assisted self-interview (ACASI). It is designed to assess the health and nutritional status of adults and children in the United States. NYC HANES is a local version of NHANES, which implies it mainly focuses on the New York area. 


## Learning objectives for today

Our main question of interest for this module is: Based on the data collected from NYC HANES, which risk factors play a role in development of hypertension?

Today, we will continue to work toward answering this by learning how to:

* Discuss your results and your initial approaches to model selection
* Explore the relationship between smoking and disease risk: why do we see the surprising patterns we see?
* Review survey weighting and how to determine what weight to use for your analysis
* Learn strategies for approaching model selection: how do you decide what variables to include in your model and how do you compare different models?
* Introduce your final project to get you to start thinking about what you may want to pursue


## Breakout group discussion for today

You'll want to load libraries, read in data, and recode variables that may be of use:
```{r}
library(tidyverse)  # core group of tidyverse packages
library(knitr)  # to make nice tables
library(ggpubr)
library(ggrepel)
library(tidyverse)
library(kableExtra)
library(survey)
library(haven)
library(broom)
library(plotrix)

dat <- read_sas('module_2/data/d.sas7bdat')
dim(dat)

hy_df <- 
  dat %>% 
    select(id = KEY,
           age = SPAGE,
           race = DMQ_14_1,
           gender = GENDER,
           diet = DBQ_1,
           income = INC20K,
           diabetes = DIQ_1,
           bmi = BMI,
           cholesterol = BPQ_16,
           drink = ALQ_1_UNIT,
           smoking = SMOKER3CAT,
           hypertension = BPQ_2,
           surveyweight = EXAM_WT)

hy_df <- hy_df %>% 
          mutate(drink = ifelse(dat$ALQ_1 == 0, 4, drink))

hy_df <- hy_df %>% mutate(race=factor(race, levels=c(100, 110, 120, 140, 180, 250), 
                      labels=c('White', 'Black/African American', 
                              'Indian /Alaska Native', 
                              'Pacific Islander', 
                              'Asian', 'Other Race')),
                     gender = factor(gender, levels=c(1,2), 
                        labels=c('Male', 'Female')),
                     diet = factor(diet, levels=c(5:1), 
                      labels=c('Poor', 'Fair', 'Good', 
                               'Very good','Excellent')),
                     income = factor(income, levels=c(1:6), 
                        labels=c('Less than $20,000','$20,000 - $39,999',
                                 '$40,000 - $59,999','$60,000 - $79,999',
                                 '$80,000 - $99,999','$100,000 or more')),
                     diabetes = factor(diabetes, levels=c(2,1,3), 
                          labels=c('No','Yes','Prediabetes')),
                     cholesterol = factor(cholesterol, levels=c(2,1), 
                             labels=c('Low value','High value')),
                     drink = factor(drink, levels=c(4,1,2,3), 
                       labels=c('Never','Weekly', 'Monthly', 'Yearly')),
                     smoking = factor(smoking, levels=c(1,3,2), 
                         labels=c('Never smoker','Former smoker','Current smoker')),
                     hypertension = factor(hypertension, levels=c(2,1), 
                              labels=c('No','Yes'))
                     )

## we will not use this in our survey design object, but will use it for visualizations below
hy_p_df <-
  hy_df %>%
  drop_na()


hypertension_design <- svydesign(
  id = ~1,
  weights = ~hy_df$surveyweight,
  data = hy_df
)
h_design_nona <- subset(hypertension_design, complete.cases(hy_df))
```



### Some points of discussion

Start by talking about your own analyses from this week:

* What surprising relationships did you see in your displays? Were there some counter-intuitive patterns? What might be causing these? How might you investigate this?

* What approach did you take to deciding what variables to include in your model?


Then, run some code together to further explore the effects of smoking on hypertension risk.

The surprise is that we see a counter-intuitive pattern where never smokers have around the same hypertension risk as current smokers:
```{r}
g_smok <- svyglm(hypertension ~ smoking, 
    family = quasibinomial(link = 'logit'), design = h_design_nona)
summary(g_smok)
```

Why is this happening? To try to answer this question, we can take the approach of using data visualizations and additional logistic regression models to explore what is going on.

Here are a few plots that help tease apart the effect of smoking on hypertension risk. What does each of these plots tell you? (NOTE: They are not well-labeled, so you may need to look at the code to figure out exactly what they are showing.)
```{r}

hy_p_df %>% count(smoking, age, hypertension) %>% group_by(smoking, age)  %>% mutate(prop = n/sum(n)) %>% filter(hypertension== "Yes") %>% 
  ggplot() + geom_point(mapping = aes(x = age, y = prop)) + 
  facet_wrap(~smoking)

hy_p_df %>% ggplot() + geom_boxplot(mapping = aes(x = smoking, y = age))


hy_p_df %>% mutate(hypBin = ifelse(hypertension == "Yes", 1, 0)) %>% ggplot() +
  geom_jitter(mapping = aes(x = age, y = hypBin, col = smoking), height = 0.05) +
  geom_smooth(mapping = aes(x = age, y = hypBin, col = smoking))

```


Rather than using age as a continuous variable, what might be a useful approach to take here?

```{r}

hy_p_df %>% mutate(ageCat = cut_number(age, 3)) %>% count(ageCat, smoking, hypertension) %>% group_by(ageCat, smoking) %>% mutate(prop = n/sum(n)) %>% filter(hypertension == "Yes") %>% 
  ggplot() +
  geom_bar(mapping = aes(x = ageCat, y =prop), stat = "identity") +
  facet_wrap(~smoking)

```


What happens when we fit different models with smoking and age?


```{r}
g_smok <- svyglm(hypertension ~ smoking, 
    family = quasibinomial(link = 'logit'), design = h_design_nona)
summary(g_smok)

g_smok_age <- svyglm(hypertension ~ smoking + age, 
    family = quasibinomial(link = 'logit'), design = h_design_nona)
summary(g_smok_age)

g_smok_age_int <- svyglm(hypertension ~ smoking*age, 
    family = quasibinomial(link = 'logit'), design = h_design_nona)
summary(g_smok_age_int)

```

OK, do you have more questions than when you started? What is driving the high rate of hypertension among older never smokers? What other hypotheses can you come up with that might explain what we see in the data?

What other variables are important predictors of hypertension status that might be related to smoking? (Income, race?)

## Additional information on survey weights

As discussed last week, in a survey sample, we often end up with "too many" samples in a category, often due to the designed sampling plan.  By "too many", we mean more than would be expected based on the make-up of the population from which we are sampling.  For example, we may have a much higher proportion of women in our sample compared to the population and a much lower proportion of men than in the population. This may happen by design if we purposely *oversample* a group that isn't well represented in the overall population.

To analyze our survey data and infer back to the population, we can use data weighting to account for the mismatch between the population and sample. If we want the data to reflect the whole population, instead of treating each data point equally, we weight the data so that taken together, our sample does reflect the entire community.

To appropriately analyze our data as a survey, we will use the [package `survey`](https://cran.r-project.org/web/packages/survey/survey.pdf){target="_blank"}, which contains functions for various types of analysis that account for survey design.

### Selecting the weights

For complex survey sampling designs, it can be complicated to calculate the weight for each individual observation. However, for many large survey data sets, such as NHANES, the appropriate weight is calculated by the organization that administers the survey and provided as a variable in the dataset. In our case study, this survey weight is calculated and provided as the `surveyweight` variable and we can simply apply this weight and perform a **survey-weighted logistic regression**.
 
Because the NYC HANES 2013-2014 data have been collected to address a variety of different questions and using different surveys, the researchers who produced the data have employed a somewhat complex weighting scheme to compensate for unequal probability of selection. Five sets of survey weights have been constructed to correspond to different sets of variables that were collected: CAPI  weight, Physical weight, Blood Lab result weight, Urine Lab results weight and Salica Lab results weight. **The determination of the most appropriate weight to use for a specific analysis depends upon the variables selected by the data analyst**. 


We will give a table to indicate each variable's origin stream:


| Variable names   |      Component      |
|---------------------------------|---------------------------------|
| age                                   | CAPI                                                                                                                                                                 |
| race                                  | CAPI                                                                                                                                                                 |
| gender                                | CAPI                                                                                                                                                                 |
| diet                                  | CAPI                                                                                                                                                                 |
| income                                | CAPI                                                                                                                                                                 |
| diabetes                               | CAPI                                                                                                                                                               |
| cholesterol                           | CAPI                                                                                                                                                                 |
| drink                                 | CAPI                                                                                                                                                                 |
| smoking                               | CAPI                                                                                                                                                                 |
| hypertension                           | CAPI                                                                                                                                                                |
| bmi                                    | EXAM                                                                                                                                                                |


When an analysis involves variables from different components of the survey, the analyst should decide whether the outcome is *inclusive* or *exclusive*, and then choose certain weights. To learn how to use weights for different purposes, refer to the particular [Analytics Guidelines](http://nychanes.org/wp-content/uploads/sites/6/2015/11/ANALYTIC-GUIDELINES-2016_V2.pdf){target="_blank"} for the survey. 

In our case, we choose EXAM weight since our analysis is exclusive. Do you remember we removed all of the observations with missing values? Now our dataset is limited to those who received a physical exam test, which means all of our survey participants have a value for the `EXAM_WT` variable. We selected this variable and renamed it as `surveyweight` in the earlier data cleaning part of this analysis. 

NYC HANES has put together some really useful documentation to give some further examples of how to select the correct weight to use in different cases: the slideshow at [Weight Adjustment](http://nychanes.org/wp-content/uploads/sites/6/2015/11/NYC-HANES-Training-Slides_part-2_08222016.pdf){target="_blank"} explains how the NYC HANES data are weighted in order to compensate for unequal probability of selection and explains how to choose the correct weight for analysis, including some hypothetical analysis scenarios. In order to determine the sources of the different variables, you can refer to the [Variable Codebook](http://nychanes.org/wp-content/uploads/sites/6/2019/01/28283961_NYC-HANES_codebook_Public_V3_011019.pdf){target="_blank"}.

## Finite population correction factor

There is one more technical detail that we need to consider when using survey data. Many methods for analysis of survey data make the assumption that **samples were collected using sampling with replacement**, i.e., any time a new participant is drawn, each member in the population has an equal chance of being sampled, even if they have already been sampled. This is not usually how surveys are actually carried out, so an adjustment may be necessary to reflect this difference. This adjustment is called the **finite population correction factor** and it is defined as:

$$FPC = (\frac{N-n}{N-1})^{\frac{1}{2}}$$
 
* `N` = population size
* `n` = sample size

In the case when the assumption above is violated (e.g. if you are sampling a sufficiently large proportion of the population), then you might sample the same persion twice. The finite population correction (FPC) is used to reduce the variance when a substantial fraction of the total population of interest has been sampled. We can find the value of `N` and `n` for our survey from the [Analytics Guidelines](http://nychanes.org/wp-content/uploads/sites/6/2015/11/ANALYTIC-GUIDELINES-2016_V2.pdf){target="_blank"}. Next let's calculate the FPC as below:

```{r}
N <-  6825749
n <- nrow(dat)
((N-n)/(N-1))^0.5
```

The FPC of our data set is very close to 1 since our sample is quite small compared to the size of the population, and we could simply ignore the FPC. But technically, since the data were collected through sampling without replacement, it is more appropriate to use it.


### Model selection

You've now fit at least one model using these data. But how do you know if it is a good model for answering our question of interest? There are many approaches to answering this question.

One way you can decide what variables to include in a model is by looking at whether the model coefficients associated with those variables are statistically significantly different from zero. (Many of you took this approach in your assignment for this week.) This tells you whether the value of the outcome (in this case log odds of having hypertension) varies as this particular input variable changes, considering all other variables in your model. So you can look at the t-statistics and p-values associated with this variable to see whether you would reject the null hypothesis that the parameters associated with this variable are zero. 


For example, we can look at these two models that we fit last week:

```{r, warning=TRUE}
g0 <- svyglm(hypertension ~ smoking, 
    family = quasibinomial(link = 'logit'), design = h_design_nona)
summary(g0)

g1 <- svyglm(hypertension ~ 
               age + race + gender + diet + income + 
               diabetes + bmi + cholesterol + drink + smoking,
             family = quasibinomial(link = 'logit'), 
             design = h_design_nona)
summary(g1)
```


Not all of the variables in our full model `g1` are considered statistically significant so we would perhaps like to remove some of them to get a reduced model. However, you may want to keep a variable in the model, even if the coefficients are not significantly different from zero, if that variable is important for the question you are trying to answer.

It's also often nice to get a value that summarizes how well your model fits the data. To do this here, we'll use an approach referred to as Akaike's "An Information Criterion," or `AIC()`. We won't discuss too many details here, but the lower an AIC for a model, the better that model fits the data. The AIC incorporates a trade-off between the number of parameters (variables) included in the model and how well the model explains the observed data:

$$ AIC = 2k - 2 \ln{\hat{L}} $$

where $k$ is the number of paramters, and $\hat{L}$ is the *likelihood* of the data, given the fitted model. Higher $k$ means higher (worse) AIC; higher $\hat{L}$ means lower (better) AIC. 

Below, we can see that `g1`, where we include multiple predictors has the lowest AIC value. Looking at this value combined with your model summary output will help you determine which of your models is the best choice for your final analysis.

```{r}
AIC(g0, g1)
```


#### Some further notes on survey weights

Remember that the weight variable that you use will depend on the set of variables that will be included in your final model. You may need to revisit this choice depending on what your final model is.

## Getting to Question 2.2

Recall Question 2.2: How do our estimates from survey-weighted logistic regression differ from those where we ignore survey weights?

To answer this, use your final model from your survey-weighted analysis and fit a standard (unweighted) logistic regression instead. How might you want to compare the results of these two models? A table? Some kind of visualization?

<center>
![](data/Finalplot.png)
</center>




## Assignment 2.3

Refine your data display and survey-weighted analysis from last week with the NYC HANES data to answer Question 2.1: What factors measured in the NYC HANES survey are associated with having hypertension?

Think about connecting each table or visualization that you make with your downstream modeling choices. How do your displays point you toward the model you end up fitting? 

Think about justifying each choice of variable in your model: can you use a visualization to do this? Look at significance of coefficients? Talk about how you are curious about a specific variable and how it influences hypertension? Compare models using AIC to decide on your final model?

Finally, start working on Question 2.2, comparing the survey-weighted results to those from an unweighted logisitic regression. What is an effective way of illustrating how the results compare?

* Submit your data display(s) and the code for your updated survey-weighted analysis in R Markdown through Github by Sunday March 14, 2020 at midnight.
* Post a screenshot of your revised data display (just the graph or table) and/or a summary table of your model results on Piazza in the "Assignment 2-3 Results" thread.  Add a sentence or two that describes what you have found so far.  You are welcome to post this anonymously to your classmates. You can also include comments about what your chose to do or questions you had as you were making the display and fitting your model.
* You may work together on this assignment, but you must submit your own data display; please credit in your assignment anyone with whom you collaborated.
* Next week in class we will continue with discussion/critiques of your model selection and comparisons.

## Looking ahead to your final projects




It is time to start thinking about your final projects, which will be the focus of the course after we wrap up Module 2. To help you get started, we have created a Google Doc where you can record your plans. This will help you organize your thoughts, find classmates working on similar questions, and help us keep track of who is working on what.

Here is link to the [doc](https://docs.google.com/document/d/1hzYiJUu3oL-vz-n4pLffufUwBiV05O_g3NwT5TBdhqg/edit?usp=sharing){target="_blank"}.

Feel free to start contributing your ideas; nothing here is set in stone, this is just a starting point that you will update in the coming weeks.

<center>
![](../module_3/Project1.png)
</center>

<center>
![](../module_3/Project2.png)
</center>

