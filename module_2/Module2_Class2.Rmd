---
title: "Class 2-2: Continuing with Module 2"
author: "Health Data Analysis Practicum (AS.280.347)"
date: "March 1, 2021"
output: 
  html_document:
    toc: true
    toc_float: 
      toc_collapsed: true
    toc_depth: 3
    number_sections: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = TRUE)
#knitr::opts_knit$set(root.dir = "/cloud/project")
```

## Module 2: Factors that are associated with development of hypertension

Recall that our main questions of interest are:

  * Question 2.1: What factors measured in the NYC HANES survey are associated with having hypertension?
  * Question 2.2: How do our estimates from survey-weighted logistic regression differ from those where we ignore survey weights?


The data science learning objectives for this module include:

  * Understand the components of a data analysis report
  * Gain experience performing data cleaning, and assessing whether you have been successful
  * Practice selecting data visualizations that fit into the context of your statistical analysis

The statistical learning objectives for this module include:

  * Gain further experience with logistic regression and selecting an appropriate model for your question
  * Understand what a survey-weighted analysis is and how/when we perform one
  * Learn how to select survey weights for unbalanced data

## Reminder: What are the data?

For this case study, we will use data from the [New York City (NYC) Health and Nutrition Examination Survey (NYC HANES)](http://nychanes.org/){target="_blank"}, modeled on the [National Health and Nutrition Examination Survey (NHANES)](https://wwwn.cdc.gov/nchs/nhanes/default.aspx){target="_blank"}. NHANES is a population-based, cross-sectional study with data collected from a physical examination and laboratory tests, as well as a face-to-face interview and an audio computer-assisted self-interview (ACASI). It is designed to assess the health and nutritional status of adults and children in the United States. NYC HANES is a local version of NHANES, which implies it mainly focuses on the New York area. 


## Learning objectives for today

Our main question of interest for this module is: Based on the data collected from NYC HANES, which risk factors play a role in development of hypertension?

Today, we will continue to work toward answering this by learning how to:

* Discuss our initial data visualizations and how they relate to the question of interest for this module
* Understand why we need to include survey weights in our analysis
* Learn about and see how to use tools designed for working with survey data in R 


## Your data visualizations

Start by loading libraries and raw data set.
```{r}
library(tidyverse)  # core group of tidyverse packages
library(knitr)  # to make nice tables
library(ggpubr)
library(ggrepel)
library(tidyverse)
library(kableExtra)
library(survey)
library(haven)
library(broom)
library(plotrix)

dat <- read_sas('./data/d.sas7bdat')
dim(dat)
```


### Example 1


```{r select-cols}
rename <- 
  dat %>% 
    select(id = KEY,
            agegroup=AGEGROUP,
            gender = GENDER,
            race = DMQ_14_1,
            hypertension = BPQ_2,
           surveyweight = EXAM_WT)

hy_df <- rename %>% 
  mutate(agegroup = factor(agegroup, levels=c(1:3), labels=c('20-39', '40-59', '60+')),
        race=factor(race, levels=c(100, 110, 120, 140, 180, 250), 
                      labels=c('White', 'Black/African American', 
                              'Indian /Alaska Native', 
                              'Pacific Islander', 
                              'Asian', 'Other Race')),
        gender = factor(gender, levels=c(1,2), 
                        labels=c('Male', 'Female')),
        hypertension = factor(hypertension, levels=c(2,1), 
          labels=c('No','Yes'))
                     )

hy_p_df <- 
  hy_df %>%
  drop_na()
table1 <- hy_p_df %>%
  count(agegroup, hypertension) %>%
  group_by(agegroup) %>%
  mutate(prop = n/sum(n))

p1<- table1 %>%
  filter(hypertension == "Yes") %>%
  ggplot() + 
  geom_bar(aes(x = agegroup, y = prop, fill = hypertension), stat = "identity") +
  ggtitle('Risk of Hypertension by Age') + 
          ylab('proportion')


table2 <- hy_p_df %>%
  count(gender, hypertension) %>%
  group_by(gender) %>%
  mutate(prop = n/sum(n))

p2<- table2 %>%
  filter(hypertension == "Yes") %>%
  ggplot() + 
  geom_bar(aes(x = gender, y = prop, fill = hypertension), stat = "identity") +
  ggtitle('Risk of Hypertension by Gender') + 
          ylab('proportion')



table3 <- hy_p_df %>%
  count(race, hypertension) %>%
  group_by(race) %>%
  mutate(prop = n/sum(n))

p3<- table3 %>%
  filter(hypertension == "Yes") %>%
  ggplot() + 
  geom_bar(aes(x = race, y = prop, fill = hypertension), stat = "identity") +
  ggtitle('Risk of Hypertension by Race') + 
          ylab('proportion')



ggarrange(p1, p2, p3, ncol=1, nrow=3)



```

The risk of hypertension seems to be higher in older age groups. The risk of hypertension seems to be similar between men and women, with men having a slightly higher risk. The risk of hypertension seems to be highest in the Black/African American and Pacific Islander race categories.


### Example 2

```{r}
rename <- dat %>% 
  select(id = KEY,age = SPAGE, race = DMQ_14_1, gender = GENDER, born = US_BORN, diet = DBQ_1, income = INC20K, diabetes = DIQ_1, bmi = BMI, cholesterol = BPQ_16, drink = ALQ_1_UNIT,smoking = SMOKER3CAT,hypertension = BPQ_2, education=EDU4CAT, surveyweight = EXAM_WT)
rename <- rename %>% 
          mutate(drink = ifelse(dat$ALQ_1 == 0, 4, drink))
hy_df <- rename %>% mutate(race=factor(race, levels=c(100, 110, 120, 140, 180, 250), 
                      labels=c('White', 'Black', 
                              'Alaska Native', 
                              'Pacific Islander', 
                              'Asian', 'Other Race')),
                     gender = factor(gender, levels=c(1,2), 
                        labels=c('Male', 'Female')),
                     born = factor(born, levels = c(1,2),
                        labels = c("US Born", "Non-US Born")),
                     diet = factor(diet, levels=c(5:1), 
                      labels=c('Poor', 'Fair', 'Good', 
                               'Very good','Excellent')),
                     income = factor(income, levels=c(1:6), 
                        labels=c('<$20k','$20k - $39k',
                                 '$40k - $59k','$60k - $79k',
                                 '$80k - $99k','>$100k')),
                     diabetes = factor(diabetes, levels=c(2,1,3), 
                          labels=c('No','Yes','Prediabetes')),
                     cholesterol = factor(cholesterol, levels=c(2,1), 
                             labels=c('Low value','High value')),
                     drink = factor(drink, levels=c(4,1,2,3), 
                       labels=c('Never','Weekly', 'Monthly', 'Yearly')),
                     smoking = factor(smoking, levels=c(3:1), 
                         labels=c('Never smoker','Former smoker','Current smoker')),
                     hypertension = factor(hypertension, levels=c(2,1), 
                              labels=c('No','Yes')),
                     education = factor(education, levels=c(1:4), labels=c('<High school', 'High school', 'Some college', 'College grad'))
                     )
hy_p_df <- 
  hy_df %>%
  drop_na()

dim(hy_p_df)

my_table <- hy_p_df %>%
  count(education, hypertension, income, race) %>%
  group_by(education) %>%
  mutate(prop =round(n/sum(n),3))
plot4 <- my_table %>%
  filter(hypertension == "Yes") %>%
  ggplot() + 
  geom_bar(aes(x = education, y = prop, fill = hypertension), stat = "identity") + labs(title = "Risk of hypertension by education")
my_table <- hy_p_df %>%
  count(education, hypertension, income, race) %>%
  group_by(income) %>%
  mutate(prop =round(n/sum(n),3))
plot5 <- my_table %>%
  filter(hypertension == "Yes") %>%
  ggplot() + 
  geom_bar(aes(x = income, y = prop, fill = hypertension), stat = "identity") + labs(title = "Risk of hypertension by income")
my_table <- hy_p_df %>%
  count(education, hypertension, income, race) %>%
  group_by(race) %>%
  mutate(prop =round(n/sum(n),3))
plot6 <- my_table %>%
  filter(hypertension == "Yes") %>%
  ggplot() + 
  geom_bar(aes(x = race, y = prop, fill = hypertension), stat = "identity") + labs(title = "Risk of hypertension by race")
ggarrange(plot4, plot5, plot6, ncol=1)
```


Based on the NYC HANES survey data, there seems to be an association between many different factors and the development of hypertension.  I have identified race, income, and education as three factors that seemed to influence risk of hypertension.  I chose these because they are generally understood to be important social determinants of health, which appears to hold true in the context of this survey.  As educational attainment increases, risk of hypertension decreases.  Making less than $20,000 per year greatly increases the risk of hypertension, while there are more moderate differences observed across other income levels. Survey participants that identified as Pacific Islanders had a greatly increased risk of hypertension as well, while Black/African American participants also had higher risk of hypertension.  Other racial groups saw similar risks of hypertension.


### Example 3

```{r}
### put recoding data here
rename <- 
  dat %>% 
    select(id = KEY,
           age = SPAGE,
           race = DMQ_14_1,
           gender = GENDER,
           born = US_BORN,
           diet = DBQ_1,
           income = INC20K,
           diabetes = DIQ_1,
           bmi = BMI,
           cholesterol = BPQ_16,
           drink = ALQ_1_UNIT,
           smoking = SMOKER3CAT,
           hypertension = BPQ_2,
           surveyweight = EXAM_WT) 


rename <- rename %>% 
          mutate(drink = ifelse(dat$ALQ_1 == 0, 4, drink))

hy_df <- rename %>% mutate(race=factor(race, levels=c(100, 110, 120, 140, 180, 250), 
                      labels=c('White', 'Black/African American', 
                              'Indian /Alaska Native', 
                              'Pacific Islander', 
                              'Asian', 'Other Race')),
                     gender = factor(gender, levels=c(1,2), 
                        labels=c('Male', 'Female')),
                     born = factor(born, levels = c(1,2),
                        labels = c("US Born", "Non-US Born")),
                     diet = factor(diet, levels=c(5:1), 
                      labels=c('Poor', 'Fair', 'Good', 
                               'Very good','Excellent')),
                     income = factor(income, levels=c(1:6), 
                        labels=c('Less than $20,000','$20,000 - $39,999',
                                 '$40,000 - $59,999','$60,000 - $79,999',
                                 '$80,000 - $99,999','$100,000 or more')),
                     diabetes = factor(diabetes, levels=c(2,1,3), 
                          labels=c('No','Yes','Prediabetes')),
                     cholesterol = factor(cholesterol, levels=c(2,1), 
                             labels=c('Low value','High value')),
                     drink = factor(drink, levels=c(4,3,2,1), 
                       labels=c('Never','Yearly', 'Monthly', 'Weekly')),
                     smoking = factor(smoking, levels=c(3:1), 
                         labels=c('Never smoker','Former smoker','Current smoker')),
                     hypertension = factor(hypertension, levels=c(2,1), 
                              labels=c('No','Yes'))
                     )

hy_p_df <- hy_df %>%
  drop_na()

dim(hy_p_df)

###above is just the recoding from class; below is the tables like in Module 1 to get percentages

my_table <- hy_p_df %>%
  count(diet, gender, hypertension) %>%
  group_by(gender, diet) %>%
  mutate(percent = round((n/sum(n)*100), 2)) 

my_table_2 <- hy_p_df %>%
  count(diabetes, hypertension) %>%
  group_by(diabetes) %>%
  mutate(percent = round((n/sum(n)*100), 2)) 

my_table_3 <- hy_p_df %>%
  count(drink, hypertension) %>%
  group_by(drink) %>%
  mutate(percent = round((n/sum(n)*100), 2)) 
my_table_3


plot1 <- my_table %>%
filter(hypertension == "Yes") %>%
ggplot() + 
  geom_bar(aes(x = diet, y = percent, fill = gender), stat = "identity", position = "dodge") +
  labs(title = "Risk of hypertension by diet status",
       subtitle = "split by sex",
       x ="Diet status",
       y = "Hypertension (%)") +
  geom_label(aes(x = diet, y = percent+2, label = percent, group = gender), position = position_dodge(width = 0.9), alpha = 0.3, size = 3.5)  +
  scale_fill_brewer(palette = "PuBuGn")
##for the first one, I don't think I would actually keep the gender split since it doesn't really address our question of interest, but it was cool 

plot2 <- my_table_2 %>%
filter(hypertension == "Yes") %>%
ggplot() + 
  geom_bar(aes(x = diabetes, y = percent), stat = "identity", position = "dodge", fill = "mistyrose2") +
  labs(title = "Risk of hypertension by diabetes status",
       x ="Diabetes status",
       y = "Hypertension (%)") +
  geom_label(aes(x = diabetes, y = percent+2, label = percent), position = position_dodge(width = 0.9), alpha = 0.3, size = 3.5)
  
  
plot3 <- my_table_3 %>%
filter(hypertension == "Yes") %>%
ggplot() + 
  geom_bar(aes(x = drink, y = percent), stat = "identity", position = "dodge", fill = "honeydew3") +
  labs(title = "Risk of hypertension by drinking status",
       x ="Drinking status",
       y = "Hypertension (%)") +
  geom_label(aes(x = drink, y = percent+2, label = percent), position = position_dodge(width = 0.9), alpha = 0.3, size = 3.5)


ggarrange(plot1, ncol=1,
          ggarrange(plot2, plot3, ncol=2, nrow=1))


```

I decided to consider hypertension in the context of food consumption. The risk of hypertension is lower among those with healthier diets and among those with higher drink consumption (which seems contrary to general beliefs). Comparing diabetes status, the risk of hypertension is highest (64%) among those with diabetes. 

I would like to compare diet status as reported compared to the variables also measured in the survey (consumption of vegetables, meat, etc.) and see if reported diet matches actual diet, measured against some baseline diet.  I wonder about many things which make me question the strength of the first display, for example. if that might explain why there are high risk percentages in the "Fair" category compared to poor and if males might report better diets than the one they "actually" consume, as measured by the other variables. 


### Example 4

```{r, warning=FALSE}
### put recoding data here
rename <-
  dat %>%
  select(id = KEY,
         age = SPAGE,
         race = DMQ_14_1,
         gender = GENDER,
         born = US_BORN,
         diet = DBQ_1,
         income = INC20K,
         diabetes = DIQ_1,
         bmi = BMI,
         cholesterol = BPQ_16,
         drink = ALQ_1_UNIT,
         smoking = SMOKER3CAT,
         hypertension = BPQ_2,
         surveyweight = EXAM_WT,
         education = EDU4CAT,
         insured = HIQ_1)

### correcting for weird sampling/NA's in variables:
rename <- rename %>%
  mutate(drink = ifelse(dat$ALQ_1 == 0, 4, drink))


### recoding variables
hy_df <- rename %>% 
  mutate(race=factor(race, levels=c(100, 110, 120, 140, 180, 250), labels=c('White', 'Black/African American', 'Indian /Alaska Native', 'Pacific Islander','Asian', 'Other Race')),
         gender = factor(gender, levels=c(1,2), labels=c('Male', 'Female')),
         born = factor(born, levels = c(1,2), labels = c("US Born", "Non-US Born")),
         diet = factor(diet, levels=c(5:1), labels=c('Poor', 'Fair', 'Good', 'Very good','Excellent')),
         income = factor(income, levels=c(1:6), labels=c('Less than $20,000','$20,000 - $39,999', '$40,000 - $59,999','$60,000 - $79,999', '$80,000 - $99,999','$100,000 or more')),
         diabetes = factor(diabetes, levels=c(2,1,3), labels=c('No','Yes','Prediabetes')),
         cholesterol = factor(cholesterol, levels=c(2,1), labels=c('Low value','High value')),
         drink = factor(drink, levels=c(1,2,3,4), labels=c('Weekly', 'Monthly', 'Yearly','Never')),
         smoking = factor(smoking, levels=c(3:1), labels=c('Never smoker','Former smoker','Current smoker')),
         hypertension = factor(hypertension, levels=c(2,1), labels=c('No','Yes')),
         education = factor(education, levels = c(1,2,3,4), labels=c('Less than high school diploma','High school diploma or GED',"Some college or associate's degree","College graduate or more")),
         insured = factor(insured, levels=c(1,2), labels=c("Insured","Not insured"))
)


hy_p_df <-
  hy_df %>%
  drop_na()

plot1 <- hy_p_df %>%
  ggplot(aes(x = insured, fill = hypertension)) +
  geom_bar(position = "fill") +
  ggtitle('distribution of hypertension by insurance status') +
  ylab('proportion')
plot2 <- hy_p_df %>%
  ggplot(aes(x = income, fill = hypertension)) +
  geom_bar(position = "fill") +
  ggtitle('distribution of hypertension by income status') +
  ylab('proportion')
ggarrange(plot1, plot2, ncol=1, nrow=2)

```

Residents with lower incomes have hypertension at (generally) higher rates than do residents with higher incomes. Residents with health insurance have hypertension at higher rates than do residents without insurance.

### Example 5

```{r}

rename <- 
  dat %>% 
    select(id = KEY,
           income = INC20K,
           diabetes = DIQ_1,
           cholesterol = BPQ_16,
           smoking = SMOKER3CAT,
           hypertension = BPQ_2)

hy_df <- rename %>% 
  mutate(income = factor(income, levels=c(1:6), labels=c('Less than $20,000','$20,000 - $39,999', '$40,000 - $59,999','$60,000 - $79,999', '$80,000 - $99,999','$100,000 or more')), 
         diabetes = factor(diabetes, levels=c(2,1,3), labels=c('No','Yes','Prediabetes')), 
         cholesterol = factor(cholesterol, levels=c(2,1), labels=c('Low value','High value')), 
         smoking = factor(smoking, levels=c(3:1), labels=c('Never smoker','Former smoker','Current smoker')),
         hypertension = factor(hypertension, levels=c(2,1), labels=c('No','Yes'))
                     )

hy_df_2 <- hy_df %>% drop_na()
plot1 <- hy_df_2 %>% 
  ggplot(aes(x = smoking, fill = hypertension)) + 
  geom_bar(position = "fill") + 
  ggtitle('Distribution of Hypertension by Smoking Status') + 
  xlab("Smoking Status") + 
  ylab("Proportion")

plot2 <- hy_df_2 %>% 
  ggplot(aes(x = cholesterol, fill = hypertension)) + 
  geom_bar(position = "fill") + 
  ggtitle('Distribution of Hypertension by Cholesterol Status') + 
  xlab("Cholesterol Status") +
  ylab("Proportion")

plot3 <- hy_df_2 %>% 
  ggplot(aes(x = diabetes, fill = hypertension)) + 
  geom_bar(position = "fill") + 
  ggtitle('Distribution of Hypertension by Diabetes Status') + 
  xlab("Diabetes Status") +
  ylab("Proportion")

ggarrange(plot1, plot2, plot3, ncol=1, nrow=3)

```

I created a couple of data displays looking at two other health effects, cholesterol and diabetes, and how the proportion of those with hypertension fell within the respective categories of the other adverse health effects. There were higher proportions of people with hypertension among people of high cholesterol, diabetics, and prediabetics. I also looked at a graph that showed the proportion of those with hypertension among the various smoking status groups and was surprised to see that there was a higher proportion of hypertension within the never smoker group compared to the former smoker and current smoker groups. 

### Some points of discussion

In your breakout groups, take 10-15 minutes to discuss the following questions that have come up in our initial examination of the NHANES data set, as it relates to hypertension:


(1) What surprising relationships did you see in your displays? Were there some counter-intuitive patterns? What might be causing these? How might you investigate this? Find one specific display that shows something unexpected and hypothesize about what could be leading to the unexpected pattern. Devise a plan for investigating whether this is the case.

(2) For each display, can you find one display choice that you would suggest changing to improve the visualization? If not, that is OK too!

(3) How would you go about looking for interactions between variables? For example, if you want to see if the difference in hypertension status by education level may also be related to income, what plot or table would you make?

<details> <summary> A few thoughts for when we return from breakout rooms </summary>
* The hypertension legend does not need to be displayed on each panel of multi-panel figures
* The order of some levels for the factors could be made more intuitive (e.g., no diabetes, then prediabetes then yes diabetes)
* From Examples 1 and 2, what variables may be correlated with one another? Age/income/education are all associated with socio-economic status, as is race. 
* From Example 4, is there something that may be contradictory?
* From Example 5, what is going on with the smoking variable? We should refer to the [Variable Codebook](http://nychanes.org/wp-content/uploads/sites/6/2019/01/28283961_NYC-HANES_codebook_Public_V3_011019.pdf){target="_blank"} to see what happened.


Some limitations/points for discussion regarding race and sex: both are extremely commonly used in epidemiological studies, like the one we are discussing here. Both have limitations in how they are measured and how they are used and understood in a data analysis. We should always strive to do our best in discussing and working with these variables. For example, in our case studies, we include a statement like:

> Note: While gender and sex are not actually binary, the data used in this analysis unfortunately only contains information for groups of individuals who self-reported as male or female. We also acknowledge that unfortunately not all ethnicities or group intersections are represented in the data. More research should be devoted to collecting data about the health of additional groups of people.

Some references about race in biomedical research:

[Examining How Race, Ethnicity, and Ancestry Data Are Used In Biomedical Research](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6640836/){target="_blank"}

[Race and health page from Wikipedia](https://en.wikipedia.org/wiki/Race_and_health){target="_blank"}

</details>

## Data analysis concerns: model framework and survey weights

Now that we have spent some time cleaning the data and looking at data visualizations, we want to use a statistical model to address our question of interest about which factors are related to the risk of hypertension.

Which model should we use? Since we are looking at whether or not someone develops hypertension, our outcome variable (`hypertension`) is **binary**. A binary outcome means a logistic regression model is a natural choice.  However, think of the nature of our dataset and how it was collected. It is data obtained from a survey, and we have to account for this during the analysis of the data.

In a survey sample, we often end up with "too many" samples in a category, often due to the designed sampling plan.  By "too many", we mean more than would be expected based on the make-up of the population from which we are sampling.  For example, we may have a much higher proportion of women in our sample compared to the population and a much lower proportion of men than in the population. This may happen by design if we purposefully *oversample* a group that isn't well represented in the overall population. Why might we want to do this?

To analyze our survey data and infer back to the population, we can use data weighting to account for the mismatch between the population and sample. If we want the data to reflect the whole population, instead of treating each data point equally, we weight the data so that taken together, our sample does reflect the entire community.

To appropriately analyze our data as a survey, we will use the [package `survey`](https://cran.r-project.org/web/packages/survey/survey.pdf), which contains functions for various types of analysis that account for survey design.

## Survey weights 

### What are survey weights?

Suppose that we have 25 students (20 male and 5 female) in our biostatistics class, and we want to talk with 5 of them to gauge their understanding of the content in the class. Although the proportion of female students in the population is small, we are very interested in getting their opinion, so we want to be sure to have some female students in our sample.  By randomly sampling 5 students from the class, it's quite possible we could end up with all male students in our sample, and we wouldn't learn anything about the female perspective in the class. 

Consider the extreme case where we are going to require that 4 of the 5 people we sample are female students, to be sure we get good information about the female perspective.  We sample 4 of the 5 female students and 1 of the 20 male students.   Do we expect this sample to represent the population? Definitely not, since there is a higher proportion of females in the sample than the population. We can correct for this by weighting our samples so that, taken together, they better reflect the composition of the population we want to learn about. 

Let's assume we sampled 4 of the 5 female students and 1 of the 20 male students from our population. Who do you think should get a higher weight in our analysis, males or females? What is your reasoning?


To calculate the survey weights, we could use the following formula:

$$
\begin{aligned}
Weight & = \frac{1}{Prob~of~being~selected~for~sample} \\
       & = \frac{1}{(Number~in~sample)/(Number~in~population)} \\
       & \\
       & =  \frac{Number~in~population}{Number~in~sample}
\end{aligned}
$$

That gives the following sample weights:

$$w_m=Male~Weight = \frac{20}{1} = 20$$

$$w_f=Female~Weight = \frac{5}{4} = 1.25$$

We can interpret these weights by saying that each male student in the sample represents 20 male students in the population and each female student in the sample represents 1.25 female students in the population.  Mathematically, we can see this as:

$$ 1~observed~male* w_m = 20~males $$ 
and 
$$ 4~observed~females * w_f = 5~females$$ 

<center>
![](data/surveyweight.jpeg)
</center>

By weighting the observations, we make the sample better represent the population.

For complex survey sampling designs, it can be complicated to calculate the weight for each individual observation. However, for many large survey data sets, such as NHANES, the appropriate weight is calculated by the organization that administers the survey and provided as a variable in the dataset. In our case study, this survey weight is calculated and provided as the `surveyweight` variable and we can simply apply this weight and perform a **survey-weighted logistic regression**.

### Selecting the weights

Because the NYC HANES 2013-2014 data have been collected to address a variety of different questions and using different surveys, the researchers who produced the data have employed a somewhat complex weighting scheme to compensate for unequal probability of selection. Five sets of survey weights have been constructed to correspond to different sets of variables that were collected: CAPI  weight, Physical weight, Blood Lab result weight, Urine Lab results weight and Salica Lab results weight. **The determination of the most appropriate weight to use for a specific analysis depends upon the variables selected by the data analyst**. 

We will give a table to indicate each variable's origin stream:


| Variable names   |      Component      |
|---------------------------------|---------------------------------|
| age                                   | CAPI                                                                                                                                                                 |
| race                                  | CAPI                                                                                                                                                                 |
| gender                                | CAPI                                                                                                                                                                 |
| diet                                  | CAPI                                                                                                                                                                 |
| income                                | CAPI                                                                                                                                                                 |
| diabetes                               | CAPI                                                                                                                                                               |
| cholesterol                           | CAPI                                                                                                                                                                 |
| drink                                 | CAPI                                                                                                                                                                 |
| smoking                               | CAPI                                                                                                                                                                 |
| hypertension                           | CAPI                                                                                                                                                                |
| bmi                                    | EXAM                                                                                                                                                                |


When an analysis involves variables from different components of the survey, the analyst should decide whether the outcome is inclusive or exclusive, and then choose certain weights. To learn how to use weights for different purposes, refer to the particular [Analytics Guidelines](http://nychanes.org/wp-content/uploads/sites/6/2015/11/ANALYTIC-GUIDELINES-2016_V2.pdf){target="_blank"} for the survey. 

In our case, we choose EXAM weight since our analysis is exclusive, i.e., we plan to restrict the samples included to those who have all of the data we are interested in looking at. Since one of the variables we are looking at is bmi, our dataset is limited to those who received a physical exam test, which means all of our survey participants have a value for the `EXAM_WT` variable. We selected this variable and renamed it as `surveyweight` in the earlier data cleaning part of this analysis. 

## Finite population correction factor

There is one more technical detail that we need to consider when using survey data. Many methods for analysis of survey data make the assumption that **samples were collected using sampling with replacement**, i.e., any time a new participant is drawn, each member in the population has an equal chance of being sampled, even if they have already been sampled. This is not usually how surveys are actually carried out, so an adjustment may be necessary to reflect this difference. This adjustment is called the **finite population correction factor** and it is defined as:

$$FPC = (\frac{N-n}{N-1})^{\frac{1}{2}}$$
 
* `N` = population size
* `n` = sample size

In the case when the assumption above is violated (e.g. if you are sampling a sufficiently large proportion of the population), then you might sample the same persion twice. The finite population correction (FPC) is used to reduce the variance when a substantial fraction of the total population of interest has been sampled. We can find the value of `N` and `n` for our survey from the [Analytics Guidelines](http://nychanes.org/wp-content/uploads/sites/6/2015/11/ANALYTIC-GUIDELINES-2016_V2.pdf){target="_blank"}. Next let's calculate the FPC as below:

```{r}
N <-  6825749
n <- nrow(dat)
((N-n)/(N-1))^0.5
```

The FPC of our data set is very close to 1 since our sample is quite small compared to the size of the population, and we could simply ignore the FPC. But technically, since the data were collected through sampling without replacement, it is more appropriate to use it.




## Incorporating survey weights into our analysis

We will read in and recode the data, as we did last week. NOTE: I have fixed the mis-coding of the smoking variable from last week. Also: we can't remove ANY data points from our set of data this time because we will be using survey weights. We will discuss how to address this below.

```{r read-data}
hy_df <- 
  dat %>% 
    select(id = KEY,
           age = SPAGE,
           race = DMQ_14_1,
           gender = GENDER,
           diet = DBQ_1,
           income = INC20K,
           diabetes = DIQ_1,
           bmi = BMI,
           cholesterol = BPQ_16,
           drink = ALQ_1_UNIT,
           smoking = SMOKER3CAT,
           hypertension = BPQ_2,
           surveyweight = EXAM_WT)

hy_df <- hy_df %>% 
          mutate(drink = ifelse(dat$ALQ_1 == 0, 4, drink))

hy_df <- hy_df %>% mutate(race=factor(race, levels=c(100, 110, 120, 140, 180, 250), 
                      labels=c('White', 'Black/African American', 
                              'Indian /Alaska Native', 
                              'Pacific Islander', 
                              'Asian', 'Other Race')),
                     gender = factor(gender, levels=c(1,2), 
                        labels=c('Male', 'Female')),
                     diet = factor(diet, levels=c(5:1), 
                      labels=c('Poor', 'Fair', 'Good', 
                               'Very good','Excellent')),
                     income = factor(income, levels=c(1:6), 
                        labels=c('Less than $20,000','$20,000 - $39,999',
                                 '$40,000 - $59,999','$60,000 - $79,999',
                                 '$80,000 - $99,999','$100,000 or more')),
                     diabetes = factor(diabetes, levels=c(2,1,3), 
                          labels=c('No','Yes','Prediabetes')),
                     cholesterol = factor(cholesterol, levels=c(2,1), 
                             labels=c('Low value','High value')),
                     drink = factor(drink, levels=c(4,1,2,3), 
                       labels=c('Never','Weekly', 'Monthly', 'Yearly')),
                     smoking = factor(smoking, levels=c(1,3,2), 
                         labels=c('Never smoker','Former smoker','Current smoker')),
                     hypertension = factor(hypertension, levels=c(2,1), 
                              labels=c('No','Yes'))
                     )

## we will not use this in our survey design object, but will use it for comparisons below
hy_p_df <-
  hy_df %>%
  drop_na()

```

## Specify the survey design

We now need to figure out how to specify the survey design and incorporate the sampling weights in our modeling steps. To help us do this, we use the function `svydesign()` in the [package `survey`](https://cran.r-project.org/web/packages/survey/survey.pdf). This function combines a data frame and all the design information needed to specify a survey design. Here is the list of options provided in this function:

* `ids`: Formula used to specify the cluster sampling design. *Cluster sampling* is a multi-stage sampling design where the total population is divided into several clusters and a simple random sample of clusters is selected. Then a sample is taken from the elements of each selected cluster. Use `~0` or `~1` as the formula when there are no clusters.

* `data`: Data frame (or database table name) containing the variables for analysis look up variables in the formula arguments.

* `weights`: Formula or vector specifying the sampling weights. 

* `fpc`: Finite population correction, `~rep(N,n)`  generates a vector of length n where each entry is N (the population size). Default value is 1. The use of fpc indicates a sample without replacement, otherwise the default is a sample with replacement. Since our finite-population correction factor is very close to 1, we omit this argument, i.e., let it take the default value.
 
* `strata`: Specification for stratified sampling.  *Stratified sampling* is a sampling design which divides members of the population into homogeneous subgroups and then samples independently in these subpopulations. It is advantageous when subpopulations within an overall population vary.
 
In our situation, we don't have any clusters or stratified sampling to specify, we just need to include the appropriate survey weights provided with the data.  We will not include a FPC, since our FPC was approximately 1.
 
Here's how we specify the design relative to our dataset, `hy_df`:

```{r}
hypertension_design <- svydesign(
  id = ~1,
  weights = ~hy_df$surveyweight,
  data = hy_df
)
```


The arguments are interpreted as the following:

* `ids = ~1` means there is no cluster sampling
* `data = hy_df` tells `svydesign` where to find the variables for analysis
* `weights= ~hy_df$surveyweight` tells it where to find the weight in our data frame

We can use `summary()` to show the results:
```{r}
summary(hypertension_design)
```

"Independent sampling design" means our sampling design is a simple random sample (SRS). By setting other parameters it is possible to specify different kinds of designs, such as stratified sampling, cluster sampling, or other multi-stage designs.


## Calculate survey-weighted summary statistics

Once we have created our `svydesign` object, we can use the convenient `svy*` functions to calculate summary statistics that account for survey design features.

First, we want to create a clean data set, where we no longer have observations with missing data. We will do this using the `subset` function since the `drop_na()` function does not work on the output of the `svydesign` function, but the `subset` function does. We can use the `complete.cases` function to identify which individuals in our `hy_df` data frame are not missing any of the variables.

```{r}
h_design_nona <- subset(hypertension_design, complete.cases(hy_df))
```


To calculate the mean and its standard error, use the function `svymean()`. The `svymean()` function calculates a weighted estimate for the mean by weighting each observation with its sampling weight. We can compare this result to ignoring the survey weights using the `mean()` and `std.error()` functions in base R.

Here we look at both the weighted and un-weighted mean BMI:

```{r}
svymean(~bmi, h_design_nona)
```

```{r}
mean(hy_p_df$bmi)
std.error(hy_p_df$bmi)
```

There is not a very large difference between these two values and their standard errors.  However, the survey-weighted results are "better" because they account for the sampling design of the HANES NYC survey.

To calculate a survey-weighted confidence interval for mean BMI value, we use the function `confint()` directly on the `svymean()` function:

```{r}
confint(svymean(~bmi, h_design_nona))
```

Statistics for subgroups are also easy to calculate with the function `svyby()`.  Here we look at mean BMI within groups defined by diet quality.
```{r}
svyby(~bmi, by=~diet, design = h_design_nona, 
      FUN = svymean)
```

If we are particularly interested in one subgroup of individuals, we can use the `subset()` to define a design for our subgroup of interest.  For example, if we are only interested in learning about the female population:
```{r}
h_design_female <- subset(h_design_nona,gender=="Female")
svymean(~bmi, h_design_female)
```

We estimate that the mean BMI for females in the population is 28.

Note that if we are limiting our analysis to a subgroup of the data, we **must** use the subset command to define a new survey design that relates to this new subpopulation.  This is because the survey weights need to be updated to reflect how the data represents this new population.  The `subset` command will appropriately update the survey weights so the analysis reflects the survey design of the subsetted data.  We **cannot** simply use a subset of the data with the original survey design. This is why we needed to start with the complete data set, not the one where we had already removed individuals with missing data.


## Survey-weighted logistic regression

### Fit a simple model

Logistic regression is widely used to when the response variable is binary.  The standard logistic regression equation can be written as:

$logit(p)= log(\frac{p}{1-p})=X^{T}\beta$, where $p=P(Y=1)=E(Y)$ 

As we mentioned above, our data comes from a survey design so we need to take survey weights into account in our analysis.  We can do that with a survey-weighted logistic regression using the `svyglm()` function from the `survey` package.

The `svyglm()` function works similarly to using `glm()` to fit a standard logistic regression model.  The only difference is that instead of using the original data set in the `data` argument within `glm()`, we instead input the survey design object from `svydesign()` in the `design` argument in `svyglm()`.

Now we can fit our survey-weighted logistic regression model and look at the summarized output. We will start with a simple model by choosing one variable, `smoking`, as a predictor:

```{r, warning=TRUE}
g <- svyglm(hypertension ~ smoking, 
    family = binomial(link = 'logit'), design = h_design_nona)
summary(g)
```

If we allow `warning = TRUE`, a warning would appear as "non-integer #successes in a binomial glm!". But everything is right here! `glm` and `svyglm` are just picky. They warn us if they detect that the no. of trials or successes is non-integral, but they go ahead and fit the model anyway. If you want to suppress the warning (and you're sure it's not a problem), use `family=quasibinomial()` instead.

```{r, warning=TRUE}
g0 <- svyglm(hypertension ~ smoking, 
    family = quasibinomial(link = 'logit'), design = h_design_nona)
summary(g0)
```


The `tidy()` function in the `broom` package can provide a dataframe representation of the model's output. Now we can see the model output as a nice dataframe!

```{r}
g_res <- tidy(g0)
g_res
```

As in standard logistic regression using `glm()`, we see the coefficient estimate, standard error, test statistic, and p-value for each term in our model.  We can still get survey-weighted confidence intervals with the `confint()` function:
```{r}
confint(g0)
```


What does the model output tell us about the relationship between predictor variables and the chance of getting hypertension? Look at the coefficient table. For the predictor variable `smoking`, the reference category is `Never smoker`. So the coefficient for `Former Smoker`, `r format(g_res$estimate[2], digits = 2)`, tells us that the log odds of hypertension for a former smoker is `r format(abs(g_res$estimate[2]), digits = 2)` higher than for a never smoker.  It makes more sense to exponentiate the coefficients and interpret them as odds ratios:
```{r}
exp(g0$coefficients)
```

The exponentiated coefficient for `Former smoker` is `r format(exp(g_res$estimate)[2], digits = 3)`, which means that former smokers have a `r round(100*(exp(g_res$estimate)[2] - 1), 0)`% increased odds of hypertension compared to never smokers. Similarly, the exponentiated coefficient for `Current smoker` is `r format(exp(g_res$estimate)[3], digits = 2)`, meaning current smokers have a `r round(100*(1-exp(g_res$estimate)[3]), 0)`% reduction in the odds of hypertension compared to those who have never smoked.  What's more, we can see the p-value for the coefficient of `Former smoker` is `r format(g_res %>% filter(term == "smokingFormer smoker") %>% pull(p.value), digits = 2)` which is < 0.05, so this difference is statistically significant. However, for `Current smoker`, the p-value is `r format(g_res %>% filter(term == "smokingCurrent smoker") %>% pull(p.value), digits = 2)`, which is > 0.05, meaning this difference is not statistically significant.


### Fit a full model

Now we can fit a full model that includes all of our variables of interest: 

```{r}
g1 <- svyglm(hypertension ~ 
               age + race + gender + diet + income + 
               diabetes + bmi + cholesterol + drink + smoking,
             family = binomial(link = 'logit'), 
             design = h_design_nona)
g1_res <- tidy(g1)
g1_res %>% as.data.frame()
```

One interesting thing is that both the coefficients and p-values for the `smoking` variables are different than in our simple model.  Why did this happen? Remember that with other variables in the model, our interpretation of the coefficients for smoking changes.  We now have to interpret them as describing the relationship between smoking and hypertension *while holding the other variables in the model constant.*  If the other variables in the model are also related to `smoking`, then the relationship between smoking and hypertension may be different once we account for the other variables compared to the relationship of smoking on its own.

Now, let's interpret the new output. Again, we will interpret exponentiated coefficients as odds ratios.  One categorical variable and one continuous variable are chosen as examples:

```{r}
exp(g1$coefficients)
```

* `smoking`: Holding all other variables constant, former smokers have a 25% increased odds of hypertension compared to those who have never smoked.  Holding all other variables constant, current smokers have 25% reduced odds of hypertension compared to those who have never smoked. However, neither of these differences is statistically significant.

* `bmi`: Holding all other variables constant, a one-unit increase in bmi 
is associated with a 7% increase in the odds of hypertension.

### Looking ahead to next week: Model selection

Not all of the variables in our full model `g1` are considered statistically significant so we would perhaps like to remove some of them to get a reduced model. Next week we will discuss approaches we can take to address this concern.

## Assignment 2.2

Refine your data display from last week with the NYC HANES data to answer Question 2.1: What factors measured in the NYC HANES survey are associated with having hypertension?

Use the `svydesign()` function to create an appropriate survey-weighted data set to use for your modeling analysis. You will need to be sure to include a variable with the appropriate survey weights in your data set.

Use the `svyglm()` function to fit a logistic regression model, with hypertension as the outcome, to begin to explore the relationships among the variables in your data set in a modeling framework. You may want to consider the variables you include based on your data visualizations or other reasons. Write a few sentences interpreting the outputs of your model. (If you included many variables, you don't need to write about all of them here.)

* Submit your data display and the code for your initial survey-weighted analysis in R Markdown through Github by Sunday (March 8, 2020) at midnight.
* Post a screenshot of your revised data display (just the graph or table) and/or a summary table of your model results on Piazza in the "Assignment 2-2 Results" thread.  Add a sentence or two that describes what you have found so far.  You are welcome to post this anonymously to your classmates. You can also include comments about what your chose to do or questions you had as you were making the display and fitting your model.
* You may work together on this assignment, but you must submit your own data display; please credit in your assignment anyone with whom you collaborated.
* Next week in class we will continue with discussion/critiques of your displays and brainstorm as a class on ideas to improve these displays, discuss the intial outputs of your survey-weighted logistic regression, and start talking about variable selection.

